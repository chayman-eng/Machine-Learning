
---
title: "Conditional Probability"
author: "Cameron Hayman"
date: "02/17/2025"

format: 
  html:
    theme: superhero  
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true
---

**Abstract:**

This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/cond.qmd) hosted on GitHub pages.

# 0. Quarto Type-setting

- This document is rendered with Quarto, and configured to embed an images using the `embed-resources` option in the header.
- If you wish to use a similar header, here's the format specification for this document:

```email
format: 
  html:
    embed-resources: true
```

# 1. Setup

**Setup Code:**

```{r}
sh <- suppressPackageStartupMessages
sh(library(tidyverse))
sh(library(caret))
wine <- readRDS(gzcon(url("https://cd-public.github.io/D505/dat/pinot.rds")))
head(wine)
```

# 2. Conditional Probability

Calculate the probability that a Pinot comes from Burgundy given it has the word 'fruit' in the description.

$$
P({\rm Burgundy}~|~{\rm Fruit})
$$

```{r}
# Create binary variable for whether 'fruit' appears in the description
wine <- wine %>%
  mutate(has_fruit = str_detect(description, regex("fruit", ignore_case = TRUE)))

# Compute conditional probability P(Burgundy | Fruit)
p_burgundy_given_fruit <- sum(wine$province == "Burgundy" & wine$has_fruit) / sum(wine$has_fruit)
p_burgundy_given_fruit
```

# 3. Naive Bayes Algorithm

Train a Naive Bayes model to classify a wineâ€™s province using:
1. An 80-20 train-test split.
2. Three features engineered from the description.
3. 5-fold cross-validation.

```{r}
# Load necessary libraries
library(naivebayes)
library(tidytext)

# Tokenize text and compute TF-IDF
word_tf_idf <- wine %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words, by = "word") %>%
  count(province, word, sort = TRUE) %>%
  bind_tf_idf(word, province, n) %>%
  arrange(desc(tf_idf))

# Select top 5 words per province based on TF-IDF scores
top_words <- word_tf_idf %>%
  group_by(province) %>%
  slice_max(tf_idf, n = 5) %>%
  ungroup() %>%
  distinct(word) %>%
  pull(word)

# Create binary features for selected words
for (word in top_words) {
  wine[[paste0("word_", word)]] <- str_detect(wine$description, fixed(word))
}

# Prepare dataset
wine <- wine %>% select(province, starts_with("word_"))
wine$province <- as.factor(wine$province)

# Train-test split (80-20)
set.seed(123)
trainIndex <- createDataPartition(wine$province, p = 0.8, list = FALSE)
trainData <- wine[trainIndex, ]
testData <- wine[-trainIndex, ]

# Train Naive Bayes model with 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)
nb_model <- train(province ~ ., data = trainData, method = "naive_bayes", trControl = train_control, tuneGrid = expand.grid(usekernel = FALSE, laplace = 1, adjust = 1))

# Predict on the test set
predictions <- predict(nb_model, newdata = testData)
predictions <- factor(predictions, levels = levels(testData$province))

# Compute Kappa statistic
conf_matrix <- confusionMatrix(predictions, testData$province)
kappa_value <- conf_matrix$overall['Kappa']
kappa_value
```

# 4. Frequency Differences

Find the three words that most distinguish New York Pinots from all other Pinots.

```{r}
# Tokenize text and compute word frequencies per province
word_counts <- wine %>%
  unnest_tokens(word, description) %>%
  count(province, word, sort = TRUE) %>%
  group_by(province) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

# Compute frequency differences
ny_freq <- word_counts %>% filter(province == "New York") %>% select(word, freq)
other_freq <- word_counts %>% filter(province != "New York") %>% group_by(word) %>% summarise(freq_other = mean(freq, na.rm = TRUE)) %>% ungroup()

# Find the most distinguishing words
word_diff <- ny_freq %>% left_join(other_freq, by = "word") %>% mutate(diff = freq - freq_other) %>% filter(!is.na(diff)) %>% arrange(desc(diff))

# Display top 3 distinguishing words
top_words_ny <- word_diff %>% slice_max(diff, n = 3) %>% select(word, diff)
top_words_ny
```

# 5. Extension

Calculate the variance of the logged word-frequency distributions for each province.

```{r}
# Compute word frequencies
word_freq <- wine %>%
  unnest_tokens(word, description) %>%
  count(province, word) %>%
  group_by(province) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

# Log transform frequencies
word_freq <- word_freq %>% mutate(log_freq = log(freq + 1))

# Compute variance of logged frequencies per province
variance_by_province <- word_freq %>% group_by(province) %>% summarise(variance = var(log_freq, na.rm = TRUE))
variance_by_province
```

